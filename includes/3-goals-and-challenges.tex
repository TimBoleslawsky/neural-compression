\section{Goals and Challenges}

\subsection{Possibility A}
\begin{itemize}
    \item Select one or more learned compression methods (for image/video, maybe telemetry streams) that perform well in lab/benchmark settings (e.g., in academic datasets).
    \item Adapt them to the constraints of automotive deployment: e.g., limited compute resources on vehicle ECUs, low latency requirements, energy/power budgets, heterogeneous data (camera + LiDAR + telemetry).
    \item Evaluate them “in practice” – meaning: on realistic vehicle sensor data (or representative subsamples), under scenarios closer to production: continuous streaming, varying environmental conditions, real-world noise/interference, embedded hardware.
    \item Measure metrics beyond pure rate-distortion: latency, throughput, memory footprint, energy consumption, robustness, interoperability with downstream ML tasks (e.g., perception, predictive maintenance) and the integration into the vehicle’s data pipeline (on-board, bus, cloud).
    \item Possibly propose modifications (network architecture trimming / quantization / hybrid learned + conventional method) to meet these constraints.
\end{itemize}
→ Problem: We would need to write C\# code and the focus is very much on computer science and not "Data Science/ Machine Learning"!

\subsection{Possibility B}
\begin{itemize}
    \item Task specific compression with Signet as the consumer. The ultimate goal is to increase the data quality for downstream data consumers.
    \item Maybe taking ideas of tokenization to inform compression.
\end{itemize}
